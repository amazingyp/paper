% !TeX root = ../main.tex

\chapter{绪论}

\section{选题背景及研究意义}%1.1
随着计算机硬件的高速发展，处理器的处理速度将会飞速变快，与此同时，我们注意到网络传输的速度也在和处理器处理速度一样快速增长，在这二者的共同影响下，数据增长的速度已经远超人们最初的想象。2018年，一项统计显示，当前全球的数据总量约为33ZB，到2025年可能增长到175ZB\cite{1}。人们在互联网上更加频繁地传播各种数据，海量的数据在互联网上传播之后，人们迫切地需要一个载体将这些数据进行合理的归档和存储，这些数据是很多应用服务的核心，如果不能高效准确地保存这些非结构化数据，这些应用就无法提供相应的服务\cite{2}。因此人们需要保存这些数据，确保服务能够高效地存储并访问它们，让用户能够方便快捷地使用应用、分享视频或图片。在这种背景下，信息的存储变得尤其重要，存储系统需要解决急剧膨胀的数据存储问题，系统结构的重点从数据的处理和传输转移到了数据存储上来。

传统的数据存储方案是在本地部署一个关系型数据库，通过数据库的操作语句来进行数据的写入与读取。由于单个数据库的性能有限，这样的存储方案无法应对大量的数据访问请求；同时，此方案存在单点问题，一旦数据库不可用，整个系统的数据都无法访问；另外，当前的企业应用中，存在大量的非结构化数据，统计表明，淘宝公司早在2010年就需要存储286亿张图片\cite{3}，占当时总存储空间的一半以上，腾讯公司维护的QQ相册服务需要存储近600亿张图片，总容量可达12PB\cite{4}，这些图片大多都是小文件，而关系型数据库很难高效地存储这些小文件。由此可见，面对大量的非结构化数据存储的需求，传统的数据存储方式显然无法满足，想要高效地存储和应用这些数据，需要解决单节点存储的传输速度问题和容灾问题等一系列缺点\cite{5}。分布式存储利用分而治之的思想，将数据分散开来，存储在各个不同的位置，解决了单点问题的同时提升了系统的性能。分布式存储系统以其在可伸缩性、易用性、可靠性和低成本等计算机系统应用方面的优势而成为应对这些挑战的很有前途的解决方案，得到了日益广泛的应用\cite{6}。

分布式存储可以分为文件存储、块存储和对象存储，这三类存储最大的区别是系统提供的访问接口和语义不同。文件存储适配POSIX存储语义，按照人们熟知的文件系统的架构来分配文件的路径，向用户提供文件访问的接口，功能最为完备。块存储提供的接口以数据块为单位，对客户端暴露出来的是“盘”或者“逻辑盘”，数据访问的语义比较简单，主要是对“盘”按照地址偏移访问数据。对象存储是一种将数据作为对象进行存储的方式，没有采用文件存储中的树状目录结构，而是采用键值对的方式，用一个文件名来定位文件，名字空间相对扁平。

存储的单位不同，系统的优势和缺陷就不一样，以文件作为存储单位，可以利用通用的接口使数据更方便地进行共享，便于人们对文件进行管理和操作，但系统设计复杂\cite{7}，当文件数量增加时，系统需要用很多额外空间保存文件的树状目录结构，对这些元数据的管理导致系统存储效率下降也会影响文件的读写性能，同时元数据与文件内容过于耦合，二者依赖过于紧密，不利于节点的扩展；以块作为存储单位，可以提供共享数据的快速访问，但缺少元数据的维护和相关的访问授权，直接的访问方式会存在安全问题\cite{8}；对象存储兼具文件存储和块存储的优点，能够将文件进行共享的同时还具有高效的文件读写速率\cite{9}。一方面对象存储没有采用文件存储中的树状目录结构，避免了目录数据在传输中的效率低的问题，扁平化数据内容存储提高了数据的读写效率，另一方面对象存储提供了更适合用户使用的接口，不再以块为单位，非常适合非结构化数据的读取和写入。

目前存在许多分布式对象存储系统，但随着数据量的增加，人们发现现有的系统存在以下几点问题。

1. 现有系统的元数据设计过于简单。在设计初期，人们秉承着简单实用的原则快速开发系统，系统中的元数据只有文件到块的简单映射，当存储的数据不断增加，元数据中需要保存大量的文件到块的映射关系，大量的元数据堆积会极大地影响系统的读写性能。

2. 分布式存储系统中需要保证文件的可靠。最初人们使用多副本冗余的方式来保护文件，在写入时会写入多份副本，防止系统单点故障导致文件丢失，这种方法写入时可以并行向系统写入数据但存储效率低；纠删码技术(Erasure Code，EC)也可以用来保护文件，但写入时需要计算校验数据，导致写延迟过高，因此人们想到可以先使用多副本技术将文件保存到系统中，等数据冷却下来后在后台执行EC任务，将文件用纠删码的形式进行存储，以此来提升系统的存储效率。但这样的过程需要对文件进行迁移，从多副本系统中把文件读出，再把文件写入纠删码系统，一份文件被读写两次，增大了系统的开销。

3. 现有系统在数据读写时大多都依赖操作系统，即使把对象数据拆分成一个个块，每个块的底层读写都需要借助Linux的文件系统，而操作系统的文件管理功能又需要一定的索引数据，如果索引数据内容过大无法全部存储在内存中，读取一个文件时往往需要进行三次IO操作，这无疑会影响系统的性能。

虽然有些开源的分布式对象存储系统能解决上面提到的部分问题，但对于冗余方式的结合使用，一直没有很好的解决方案。一些系统只提供了单一的冗余策略，如果只采用多副本的策略，则系统存储效率低，只采用纠删码的策略则写入和恢复读时性能差。一些系统虽然提供了两种冗余策略，但是需要为不同的冗余策略部署两套不同的系统，在进行多副本存储到纠删码存储的转移时，需要进行数据的跨系统迁移和元数据的重建，切换成本较高。除此之外，直接使用开源系统或对开源系统二次开发后对外提供服务有潜在的风险，一旦开源系统被发现漏洞就会被针对性地攻击，危害数据安全；另外开源系统的定制化较差，无法高效低成本地实现自己的业务需求；而且有些开源系统有开源协议上的限制，要求二次开发后的系统强制开源，这对商用软件而言是无法接受的。

为了解决上述问题，本文设计并实现了一个分布式对象存储系统，该系统采用基于条带的分配模式，将对象以条带的形式进行组织，条带由多个大小相等的数据块组成。在元数据压力方面，由于系统中多了一层文件到条带的映射，元数据中无需保存大量的文件到块的映射，只需用很小的空间保存文件到条带的映射，而条带到块的映射可以利用条带与块的内在数学关系进行推算，由于块的id和条带的id具有线性的关联关系，因此只需得到条带的id，再根据系统内配置的条带的参数，就可以知道这个条带内块的分布信息，无需使用额外的存储空间保存，这样元数据中需要保存的内容就得到了压缩；在保证文件可靠方面，本文设计的条带兼顾了多副本形式和纠删码形式的存储，条带内部划分出的数据块能够同时为对象的多副本存储和纠删码存储预留逻辑空间，可以允许在写入时使用多副本存储，等待数据冷却进行转移时，直接将冗余的副本进行删除回收，无需进行文件的迁移，大大降低了系统的开销；在数据读写方面，本文为这种分配模式设计了相应的磁盘划分方案，应用此方案可以在读取对象数据时跳过文件系统的限制，磁盘内无需保存文件的索引节点，只需给出相关的参数就可以利用存储节点提供的接口从裸盘中写入或获取所需的数据，提高了读写效率。

\section{国内外研究现状}%1.2
\subsection{国外研究现状}%1.2.1
对象存储的雏形最早可以追溯到1980年，麻省理工大学的SWALLOW项目提出了以对象为单位进行存储\cite{10}。此后，卡内基梅隆大学在他们的Network-Attached Security Disks\cite{11}（NASD）项目中搭建了一个分布式对象存储系统，使用基于对象接口的附网磁盘对对象进行直接操作，通过加密和证书的认证机制保证系统的安全性。NASD的成功为对象存储的研究打下了深厚的基础，此后有许多关于对象存储的研究是基于NASD开展的，比如在1999年开始研发的Lustre\cite{12}。

新世纪以来，分布式存储技术继续蓬勃发展，2003年谷歌发布了The Google File System\cite{13}（GFS），这篇论文极大地影响了分布式存储的架构，之后的分布式存储系统或多或少地都受其影响。它的主要思想是将文件的实际数据和元数据分开存放，数据被分成了一个个chunk，这些chunk可以分布在系统的各个节点中。GFS中的节点被分为主节点（Master）和块服务器节点（Chunk Server），文件的元数据存放在Master中，实际的数据则在Chunk Server中存放。谷歌并没有将GFS开源，但GFS架构简单，且它的可行性有谷歌的实践来进行保证，因此有许多公司跃跃欲试，纷纷尝试实现此系统，其中最为著名的是Hadoop Distributed File System\cite{14}（HDFS），HDFS可以被视为是GFS的一种开源实现。HDFS参考GFS的架构，将GFS中的相关组件进行了复现，同时加入了一些新的组件来解决GFS中存在的性能问题，被很多公司使用，用来保存大批量的离线数据。

对于中小型企业来说，自己部署一个大型的分布式存储系统成本较高，它们更倾向于使用云服务的方法来保存自己的数据。Amazon公司是最早提供对象存储服务的厂商，它们推出了Amazon Smaple Storage Service\cite{15}（S3），用户可以使用S3提供的服务来方便快捷地存储自己的数据，这个系统定义了一套操作对象存储的RESTful风格的API\cite{16}，这套API成为了对象存储的行业标准，许多开源的对象存储系统都会遵循Amazon S3协议。

分布式对象存储不仅可以直接暴露给用户使用，还可以以它为基础，构建其他类型的分布式存储系统，Ceph\cite{17,18}就是一个很好的例子，Ceph为用户提供了对象存储、文件存储和块存储的接口，但它们的底层存储，都依赖Ceph的基础存储系统Reliable Autonomic Distributed Object StoreCeph\cite{19,20}（RADOS）。RADOS本质就是一个分布式对象存储系统，是Ceph的实现基础，它提供了高度可靠和自动管理的对象存储功能，为Ceph提供了强大的分布式存储能力。在Ceph中，所有数据都以对象的形式在RADOS中进行存储，可以有效保证数据的一致性和可靠性。在RADOS中，由Object Store Device（OSD）负责数据的存储，RADOS的设计理念是将数据分布在整个Ceph存储集群的多个OSD上。这使得存储集群可以水平扩展，支持海量数据的处理，并具备高性能和负载均衡能力。

不同于GFS等使用主从架构的分布式存储系统，RADOS使用了去中心化的解决方案，数据存储的具体位置不依赖元数据，而是使用Controlled Repplication Under Scalable Hashing\cite{21}（CRUSH）算法进行寻址和负载均衡，当存储集群的节点发生变化或存储容量发生变化时，RADOS会自动调整数据的分布，确保每个OSD上存储的数据量相对均衡。但也正因如此，数据的存放位置由算法决定，数据的分布在系统内趋于平均，如果想要进行多副本到纠删码的转换，难免会出现跨机架甚至跨机房的网络流量，而如果修改算法则会导致数据分布不均，影响系统性能，因此Ceph不能很好地实现多副本与纠删码结合使用。

近些年来，随着对象存储技术的成熟，越来越多的数据被存储到了对象存储系统中，随着越来越多的敏感数据的积累，隐私控制越来越重要，数据管理员执行的隐私控制可以让其完全访问数据，已不符合人们的要求。为了解决这一问题，Egeon\cite{22}允许用户声明性地设置共享数据的隐私策略，用户可以通过数据转换的组合来构建复杂的数据保护服务，Egeon在读取请求时调用这些转换，充分地保护了数据的安全。

为了节省存储成本、实现更高的性能，文献\cite{23}介绍了一种基于Db2 Warehouse的对象存储系统，它使用LSM树作为存储子系统一部分，能够在对象存储中高效地存储数据页，并通过应用特殊技术来最小化读写延迟以及读写放大。

\subsection{国内研究现状}%1.2.2
以上介绍的GFS和HDFS都是针对大文件设计的存储系统，在存储小文件时需要保存大量元数据，导致存储效率低下，无法应对海量小文件存储。据统计，淘宝后台存储了大量的小图片，8K以下的占总数的61$\%$\cite{24}，因此淘宝研发了Tabao File Sytem\cite{25}(TFS)。TFS在设计时为存储小文件做出了很多新颖的设计，比如TFS为了避免查找目录树对性能的影响，使用键值存储的方式来查找文件，同时用编号来标识小文件。在读写方面的考虑上，TFS从实际应用场景出发，重点考虑读多写少的场景，将多个小文件合并到一个物理文件中，物理文件聚集后以块的形式存储，既避免了重复写入文件的开销，也提高了读取数据的效率。在可用性方面，TFS采用双机热备\cite{26}方案来保证数据的高可用，数据的可靠性依靠三副本的冗余方式来保证，默认情况下只有数据全部被同步后才将结果返回给客户端。虽然TFS采用的是中心化的架构，能够决定数据的存储位置，在多副本到纠删码的转换时能减少网络流量，但是系统的元数据中记录了文件到机器的映射，在多副本到纠删码转换时，需要重新修改元数据信息，增加系统的开销，因此TFS也不能很好地实现多副本与纠删码结合使用。

在性能上，人们利用数据间的相关性，提出了一个策略驱动的框架Cora\cite{27}，它能有效地提取数据的相关性，改变相关对象在集群中的分布以及相关对象的存储方式，在读取时预取云对象存储系统中的相关对象，显著提高云对象存储系统的性能，吞吐量和延迟都得到了一定的优化。

近些年来，对象存储技术一直在不断发展，越来越多的企业研究机构、大学和研究人员对其进行了相关的分析。在对对象存储进行研究时，主要集中在其运用领域、数据安全性能、和集群稳定性等方面。

对象存储系统的一个发展趋势是越来越专业化，企业用户、个人用户、研究机构等不同的用户对对象存储系统的需求不同，它们需要根据自己的需求，对原有的系统进行改动，提升系统的效率，将对象存储系统打造成针对某一领域的存储系统\cite{28,29}。 例如，为了存储医学影像，人们利用对象存储系统技术，开发了MOSS系统\cite{30}，MOSS使用无中心节点的系统布局，采取纠删码技术使得医学影像图片均匀的存放在各个存储节点，每个节点负载均衡，后续在此系统之上搭建了医学影像的检索系统，加快了使用和筛选医学影像的效率；新华社为了储存用户上传和入库的稿件中照片、音乐、视频等文件，基于开源的MinIO，改造原有的采编融媒平台文件服务接口\cite{31}，由最初的通过NAS的存储路径方式改造成对象存储的http接口方式进行访问，新开发了MinIO文件上传和文件注册接口，实现了通过S3协议的对象存储域名完成文件注册功能。

很多企业和研究人员也对对象存储系统的数据安全问题进行过深入研究。国内的云存储厂商越来越重视其服务的数据安全性，因为一旦数据泄露，将会造成巨大的损失，也会影响公司的声誉，因此它们的服务大都可以极大地保证用户的数据安全。并且，越来越多的研究人员开始重视文件对称加密\cite{32}、文件容错处理等安全性管理措施，并尝试将这些方法应用到对象存储系统中。

\section{本文的主要工作}%1.3
本文为了解决现存分布式对象存储系统存在的问题，以低成本和大量小文件存储为目标，设计并实现了一个分布式对象存储系统。通过需求分析明确了系统的需求，给出了系统的设计与实现方案，将系统划分为用户数据管理模块、桶数据管理模块、文件管理模块和文件交互模块这四个功能模块，同时也给出了这四个功能模块依赖的对象数据存储模块的设计与实现方案，在对象数据存储模块中，对象以条带的形式进行分配和存储，利用基于条带的分配方式，减少元数据的存储压力，优化系统保证文件可靠性的方式，提升系统的整体性能。通过这些模块的相互配合，实现了用户对对象数据的管理和存储需求，为用户提供了高可用、可扩展的存储服务。本人主要完成如下工作:

1. 参与整个系统的技术调研和需求评审工作。

2. 参与系统功能模块的方案设计，并负责完成这些模块中核心功能的开发。

3. 参与系统对象数据存储模块的方案设计，包括基于条带分配的分配模式和与之相适配的磁盘划分的设计，并负责完成这些方案中核心功能的开发工作。

4. 参与系统的测试环境部署，并对系统的功能性需求和非功能性需求进行测试，同时也与同类系统进行了对比测试与分析。

\section{本文的组织结构}%1.4
本篇论文的章节安排如下：

第一章，绪论：介绍当前互联网中数据量激增的背景，阐述了分布式存储以及对象存储系统的优越性和必要性，同时分析了当前对象存储系统的国内外发展现状，得出当前系统存在的缺点和问题。

第二章，相关技术简介：介绍对象存储系统的相关背景知识，同时介绍一些经典的分布式存储系统。另外本章对本系统所使用到的具体技术进行详尽的阐述，一方面介绍了冗余恢复技术，这是本系统重点优化的一个部分，另一方面将介绍本应用所使用的数据库MongoDB，并分析MongoDB的特点和高可用的部署方式。 

第三章，需求分析：根据当前的实际应用背景，分析系统的目标用户，得出系统所需的特性，同时也分析了用户对分布式对象存储系统的功能性需求和非功能性需求。

第四章，概要设计：该部分主要用来描述该对象存储系统的概要设计。首先介绍系统的整体架构，然后根据需求分析中的内容以及系统的架构，分别介绍了每个模块的概要设计方案。

第五章，详细设计与实现：从概要设计出发，利用已有的设计方案，结合软件工程的开发思想，详尽地阐述了项目中每个模块的设计方案和实现细节。

第六章，系统测试与分析：在实现该应用之后，我们要结合该系统的需求分析和功能，对该存储系统进行测试。此章节给出了系统的功能性需求的测试结果和非功能性需求的测试结果，同时还给出了和其他同类产品的对比测试与分析。

第七章，总结与展望。首先对论文进行简单的总结，同时对系统存在的不足进行描述分析，并分析了系统未来可以改进的方向。